{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to ECE421: Introduction to Machine Learning\n",
        "\n",
        "This is your first assignment of ECE421. In this assignment, wou will\n",
        "* familiarize yourself with Google colab, NumPy, and scikitlearn\n",
        "* Implement a simple Perceptron\n",
        "* Implement linear regression\n",
        "\n",
        "This file is a Jupyter Notebook. You can double-click on section headers to show code and run each section with Shift+Enter."
      ],
      "metadata": {
        "id": "0Zn0G3fj7o3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "**IMPORTANT:** You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."
      ],
      "metadata": {
        "id": "yBO450Gc7fzq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jPi-4bIw15xj"
      },
      "outputs": [],
      "source": [
        "#@title mount your Google Drive\n",
        "#@markdown Your work will be stored in a folder called `ece421_f2024` by default to prevent Colab instance timeouts from deleting your edits.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "from importlib import reload\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title set up mount symlink\n",
        "\n",
        "DRIVE_PATH = '/content/gdrive/MyDrive/ece421_f2024'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## make a symlink\n",
        "SYM_PATH = '/content/ece421_f2024'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH"
      ],
      "metadata": {
        "id": "Q5f5ElCI2E3H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title apt install requirements\n",
        "\n",
        "!apt update\n",
        "!apt install -y --no-install-recommends \\\n",
        "        build-essential \\\n",
        "        curl \\\n",
        "        git \\\n",
        "        gnupg2 \\\n",
        "        make \\\n",
        "        cmake \\\n",
        "        ffmpeg \\\n",
        "        swig \\\n",
        "        libz-dev \\\n",
        "        unzip \\\n",
        "        zlib1g-dev \\\n",
        "        libglfw3 \\\n",
        "        libglfw3-dev \\\n",
        "        libxrandr2 \\\n",
        "        libxinerama-dev \\\n",
        "        libxi6 \\\n",
        "        libxcursor-dev \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        lsb-release \\\n",
        "        ack-grep \\\n",
        "        patchelf \\\n",
        "        wget \\\n",
        "        xpra \\\n",
        "        xserver-xorg-dev \\\n",
        "        ffmpeg\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y"
      ],
      "metadata": {
        "cellView": "form",
        "id": "maKSrlS86DYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title clone homework repo\n",
        "\n",
        "%cd $SYM_PATH\n",
        "!git clone https://github.com/erfanmeskar/ece421fall24_assignments.git\n",
        "ASSIGNMENT_PATH = '/content/gdrive/MyDrive/ece421_f2024/ece421fall24_assignments/A1'\n",
        "%cd $ASSIGNMENT_PATH\n",
        "%pip install -r requirements_colab.txt"
      ],
      "metadata": {
        "id": "FfRhDABd94oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A little bit of practice with scikitlearn and numpy"
      ],
      "metadata": {
        "id": "4akJkAZfMS4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASSIGNMENT_PATH = '/content/gdrive/MyDrive/ece421_f2024/ece421fall24_assignments/A1'\n",
        "%cd $ASSIGNMENT_PATH\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "from importlib import reload\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "import PerceptronImp\n",
        "import LinearRegressionImp"
      ],
      "metadata": {
        "id": "oMmwfKB-GFkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using `sklearn`, we load the *Iris dataset* and split it into a train set and\n",
        "# a test set.\n",
        "X_train, y_train = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train[50:], y_train[50:],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# we modify the labels into +1 and -1,\n",
        "# so that it would be suitable for binary classification.\n",
        "y_train[y_train != 1] = -1\n",
        "y_test[y_test != 1] = -1\n",
        "y_train[y_train == 1] = 1\n",
        "y_test[y_test == 1] = 1"
      ],
      "metadata": {
        "id": "LlRav5sQHJWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Investigate the dataset\n",
        "\n",
        "Let's investigate the dataset by taking a look at the shape of the training dataset and the its first datapoint.\n",
        "\n",
        "Your dataset must contain 80 datapoints in 4-dimensional space."
      ],
      "metadata": {
        "id": "YRi9USN_M5qa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train is of type {type(X_train)}, with shape {X_train.shape}\")\n",
        "print(f\"y_train is of type: {type(y_train)}, with shape {y_train.shape}\")\n",
        "display(Markdown(rf'Hence, $N={X_train.shape[0]}$ and $d={X_train.shape[1]}$'))\n",
        "\n",
        "print(\"\\nThe first datapoint:\")\n",
        "display(Markdown(rf'$(\\underline{{x}}_1, y_1) = ({X_train[0,:]}, {y_train[0]})$'))\n"
      ],
      "metadata": {
        "id": "jcRCYNBFHqLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1.1: Implementing Pocket Algorithm Using `Numpy`"
      ],
      "metadata": {
        "id": "C9iaSZnwH0AE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Looking into the `pred` function\n",
        "\n",
        "A Perceptron decision rule is specified by a weight vector of size (d+1)., i.e. $h_{\\underline{w}}(\\underline{x})=\\text{sign}(\\underline{w}^T\\underline{x})$, where\n",
        "\n",
        "$\\begin{align}\n",
        "\\underline{w}&=(w_0, w_1, \\ldots, w_d)\\\\\n",
        "\\underline{x}&=(x_0=1, x_1, \\ldots, x_d).\n",
        "\\end{align}$\n",
        "\n",
        "In what follows, we first generate three random datapoints with $d$ cordinates. Then augment the datapoints by adding one more cordinate which is set to 1. Next, we generate a random weight vector and use `perceptronImp.pred` function to see the predicted labels for each datapoint."
      ],
      "metadata": {
        "id": "2KYdwh3HZ5HG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N, d = 4, 2\n",
        "np.random.seed(42)\n",
        "\n",
        "X = np.random.normal(size=(N, d))\n",
        "print(f\"input datapoint = \\n{X}\")\n",
        "y = np.array([-1, -1, 1, 1])\n",
        "print(f\"and their true labels = \\n{y}\")\n",
        "\n",
        "X_aug = np.hstack((np.ones(shape=(N, 1)), X))\n",
        "print(f\"\\ninput datapoint after augmenting = \\n{X_aug}\")\n",
        "\n",
        "w = np.random.normal(size=(d+1,))\n",
        "print(f\"\\nweight vector = \\n{w}\")\n",
        "\n",
        "print(\"\\nPredicted labels:\")\n",
        "for i in range(N):\n",
        "  display(Markdown(rf'$\\hat{{y}}_{i} = {PerceptronImp.pred(X_aug[i, :], w)}$'))"
      ],
      "metadata": {
        "id": "SttQmNznhkX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## $E_{\\text{in}}(\\underline{w})$\n",
        "\n",
        "Now it is your turn to implement the `errorPer` function in the file `perceptronImp.py` to find the in-sample error, *i.e.*, the average number of points that are missclasified.\n",
        "\n",
        "\\\\\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `errorPer` in `perceptronImp.py`\n",
        "\n",
        "\\\\\n",
        "**NOTE:** Don't forget to consider the case of the datapoint being on the hyperplan. In this case, you should have a missclasification."
      ],
      "metadata": {
        "id": "xLtHFmCfn1OH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test 1\n",
        "#@markdown for the example above, your errorPer function output must be 0.25\n",
        "\n",
        "# reloding the perceptronImp module to implement your changes to the file\n",
        "reload(PerceptronImp)\n",
        "\n",
        "# for the example above, your errorPer function output must be 0.25\n",
        "if PerceptronImp.errorPer(X_aug, y, w) == 0.25:\n",
        "  print(\"test 1 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 1 result: Incorrect\")"
      ],
      "metadata": {
        "id": "AwZtT35RZhg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test 2\n",
        "#@markdown this cell tests if you could successfully handle the case in which a point is on the hyperplane.\n",
        "\n",
        "# reloding the perceptronImp module to implement your changes to the file\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[1, 2],\n",
        "              [1, 3]])\n",
        "\n",
        "y = np.array([1, -1])\n",
        "yp = np.array([-1, -1])\n",
        "\n",
        "w = np.array([-2, 1])\n",
        "\n",
        "# for this example, your errorPer function output must be 1. Note that the first\n",
        "# point is exactly on the hyperplane. Thus, this point must be considered as a\n",
        "# missclassification, regardless of its true label.\n",
        "if PerceptronImp.errorPer(X, y, w) == 1 and PerceptronImp.errorPer(X, yp, w) == 1:\n",
        "  print(\"test 2 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 2 result: Incorrect\")"
      ],
      "metadata": {
        "id": "RQ0iRvLjtgNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit your Perceptron\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `fit_perceptron` in `perceptronImp.py`\n"
      ],
      "metadata": {
        "id": "mpsTRqbnx8Zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test 3\n",
        "#@markdown this cell tests if your Perceptron can be trained over a simple mode.\n",
        "\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[2],\n",
        "              [3]])\n",
        "y = np.array([1, -1])\n",
        "\n",
        "w = PerceptronImp.fit_perceptron(X, y)\n",
        "\n",
        "if -w[0]/w[1] < X[1, 0] and -w[0]/w[1] > X[0, 0]:\n",
        "  print(\"test 3 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 3 result: Incorrect\")\n"
      ],
      "metadata": {
        "id": "XlKSUNqixOUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `confMatrix` in `perceptronImp.py`"
      ],
      "metadata": {
        "id": "Q7joOQe--DYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test 4\n",
        "#@markdown this cell is simple tests for your confMatrix.\n",
        "\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[1, 1],\n",
        "              [1, -1],\n",
        "              [-1, 1],\n",
        "              [-1, -1]])\n",
        "y = np.array([1, 1, -1, -1])\n",
        "\n",
        "conf = PerceptronImp.confMatrix(X, y, np.array([0, 0, 1]))\n",
        "\n",
        "if np.sum(conf == np.ones(2)) == 4:\n",
        "  print(\"test 3 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 3 result: Incorrect\")"
      ],
      "metadata": {
        "id": "kemf0lfk4PsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1.2: Pocket Algorithm Using `scikit-learn`\n",
        "\n",
        "In this part, you will use the `scikit-learn` library to train the binary linear classification model.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `test_SciKit` in `perceptronImp.py`"
      ],
      "metadata": {
        "id": "HlvRT92uBPMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test 5\n",
        "#@markdown this cell tests if your scikit Perceptron works for a simple linearly separable dataset.\n",
        "\n",
        "reload(PerceptronImp)\n",
        "\n",
        "X = np.array([[1, 1],\n",
        "              [1, -1],\n",
        "              [-1, 1],\n",
        "              [-1, -1]])\n",
        "y = np.array([1, 1, -1, -1])\n",
        "\n",
        "conf = PerceptronImp.test_SciKit(X, X, y, y)\n",
        "\n",
        "if np.sum(conf == 2*np.eye(2)) == 4:\n",
        "  print(\"test 3 result: Good Job!\")\n",
        "else:\n",
        "  print(\"test 3 result: Incorrect\")"
      ],
      "metadata": {
        "id": "4tUZECoE_Trm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Your Pocket Algorithm with `scikit-learn`\n",
        "\n",
        "Let's see how your model and the one from `scikit-learn` perform with Iris dataset."
      ],
      "metadata": {
        "id": "5pYRLK9EFb5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reload(PerceptronImp)\n",
        "# Pocket algorithm using Numpy\n",
        "w = PerceptronImp.fit_perceptron(X_train, y_train)\n",
        "my_conf_mat = PerceptronImp.confMatrix(X_test, y_test, w)\n",
        "\n",
        "# Pocket algorithm using scikit-learn\n",
        "scikit_conf_mat = PerceptronImp.test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Print the result\n",
        "print(f\"{12*'-'}Test Result{12*'-'}\")\n",
        "print(\"Confusion Matrix from Part 1a is: \\n\", my_conf_mat)\n",
        "print(\"\\nConfusion Matrix from Part 1b is: \\n\", scikit_conf_mat)"
      ],
      "metadata": {
        "id": "hm30HlT-D4ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2.1: Linear Regression Using `NumPy`"
      ],
      "metadata": {
        "id": "YBN4fBYqIZMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mean Squared Error (MSE)\n",
        "\n",
        "**TODO:** edit the function `mse` to find $E_{\\text{in}}(\\underline{w})=\\frac{1}{N}||\\underline{y}-\\underline{\\hat{y}}||^2$. You find the `pred` function in `LinearRegressionImp.py` useful.\n",
        "\n",
        "functions to edit:\n",
        "* `mse` in `LinearRegressionImp.py`"
      ],
      "metadata": {
        "id": "NIGVCN2NJETY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit Your Model\n",
        "\n",
        "**TODO:** edit the function `mse` to find $E_{\\text{in}}(\\underline{w})=\\frac{1}{N}||\\underline{y}-\\underline{\\hat{y}}||^2$. You may find the `pred` function in `LinearRegressionImp.py` useful. Modify the function `fit_LinRegr` to implement the exact computation of the solution for linear regression\n",
        "using the NumPy library functions via the least squares method.\n",
        "\n",
        "functions to edit:\n",
        "* `mse` in `LinearRegressionImp.py`\n",
        "* `fit_LinRegr` in `LinearRegressionImp.py`"
      ],
      "metadata": {
        "id": "E44XytTIKXlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test 6\n",
        "#@markdown When we input a singular matrix, the function linalg.inv often returns an error message.\n",
        "\n",
        "#@markdown In this example, we constrcuted a simple but trouble making $X$. With this X, in your fit_LinRegr(X, y) implementation, is your input to the function linalg.inv a singular\n",
        "#@markdown matrix? why?\n",
        "\n",
        "#@markdown Replacing the function `linalg.inv` with `linalg.pinv`, you should get the model’s weight and the “NO\n",
        "#@markdown ERROR” message. Explain the difference between `linalg.inv` and `linalg.pinv`.\n",
        "\n",
        "reload(LinearRegressionImp)\n",
        "\n",
        "X = np.asarray([[1, 2],\n",
        "                [2, 4],\n",
        "                [3, 6],\n",
        "                [4, 8]])\n",
        "y = np.asarray([1, 2, 3, 4])\n",
        "\n",
        "try:\n",
        "  w = LinearRegressionImp.fit_LinRegr(X, y)\n",
        "  print(\"weights: \", w)\n",
        "  print(\"NO ERROR\")\n",
        "except:\n",
        "  print(\"ERROR\")"
      ],
      "metadata": {
        "id": "ID5-07FuIfWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2.2: Linear Regression Using `scikit-learn`\n",
        "\n",
        "In this part, you will use the `scikit-learn` library to train the linear regression model.\n",
        "\n",
        "**TODO:**\n",
        "\n",
        "functions to edit:\n",
        "* `test_SciKit` in `LinearRegressionImp.py`"
      ],
      "metadata": {
        "id": "bU0ygOOnQPgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing Your Linear Regression Implementation with `scikit-learn`\n",
        "\n",
        "Let's see how your model and the one from `scikit-learn` perform with diabetes dataset."
      ],
      "metadata": {
        "id": "ST2lnmf5Q7na"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reload(LinearRegressionImp)\n",
        "\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, y_train = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)\n",
        "\n",
        "w = LinearRegressionImp.fit_LinRegr(X_train, y_train)\n",
        "\n",
        "#Testing Part 2a\n",
        "e = LinearRegressionImp.mse(X_test, y_test, w)\n",
        "\n",
        "#Testing Part 2b\n",
        "scikit = LinearRegressionImp.test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(f\"Mean squared error from Part 2a is {e}\")\n",
        "print(f\"Mean squared error from Part 2b is {scikit}\")"
      ],
      "metadata": {
        "id": "v1R6rPR1O6-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}