{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1LXbdTs1q8_"
      },
      "source": [
        "# Welcome to the Second Assignment of ECE421\n",
        "\n",
        "In this assignment, wou will\n",
        "* Implement different gradient descent optimizers, namely Heavy Ball Momentum, Nesterov Accelerated Gradient, and ADAM\n",
        "* Implement multiclass logistic regression\n",
        "* Trian your multiclass logistic regression with different optimizers\n",
        "* Implement a simple K-means Clustering\n",
        "\n",
        "This file is a Jupyter Notebook. You can double-click on section headers to show code and run each section with Shift+Enter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJFeX6i21uLl"
      },
      "source": [
        "# 0.1 Setup\n",
        "\n",
        "**IMPORTANT:** You will need to make a copy of this notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMYLNwqn1njW",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title mount your Google Drive, set up mount symlink, and apt install requirements\n",
        "#@markdown Your work will be stored in a folder called `ece421_f2024` by default\n",
        "#@markdown to prevent Colab instance timeouts from deleting your edits.\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "from importlib import reload\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "## setting the path parameters and creating the folder if needed\n",
        "DRIVE_PATH = '/content/gdrive/MyDrive/ece421_f2024'\n",
        "DRIVE_PYTHON_PATH = DRIVE_PATH.replace('\\\\', '')\n",
        "if not os.path.exists(DRIVE_PYTHON_PATH):\n",
        "  %mkdir $DRIVE_PATH\n",
        "\n",
        "## make a symlink\n",
        "SYM_PATH = '/content/ece421_f2024'\n",
        "if not os.path.exists(SYM_PATH):\n",
        "  !ln -s $DRIVE_PATH $SYM_PATH\n",
        "\n",
        "!apt install the requirements\n",
        "!apt update\n",
        "!apt install -y --no-install-recommends \\\n",
        "        build-essential \\\n",
        "        curl \\\n",
        "        git \\\n",
        "        gnupg2 \\\n",
        "        make \\\n",
        "        cmake \\\n",
        "        ffmpeg \\\n",
        "        swig \\\n",
        "        libz-dev \\\n",
        "        unzip \\\n",
        "        zlib1g-dev \\\n",
        "        libglfw3 \\\n",
        "        libglfw3-dev \\\n",
        "        libxrandr2 \\\n",
        "        libxinerama-dev \\\n",
        "        libxi6 \\\n",
        "        libxcursor-dev \\\n",
        "        libgl1-mesa-dev \\\n",
        "        libgl1-mesa-glx \\\n",
        "        libglew-dev \\\n",
        "        libosmesa6-dev \\\n",
        "        lsb-release \\\n",
        "        ack-grep \\\n",
        "        patchelf \\\n",
        "        wget \\\n",
        "        xpra \\\n",
        "        xserver-xorg-dev \\\n",
        "        ffmpeg\n",
        "!apt-get install python-opengl -y\n",
        "!apt install xvfb -y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.2. **DANGER:** Pulling the updated version of the repository.\n",
        "\n",
        "Before we move on, make sure you have stored your modified/submitted version of A1 somewhere on your local machine. After running this cell, your modifications to A1 will be lost.\n",
        "\n",
        "## **WARNING:** You only need to run this cell once, to fetch the starter code for A2. Your changes to A1 and A2 implementation will be lost after each time you run the folowwing cell.\n",
        "\n",
        "\n",
        "## **WARNING:** before runnig this cell, make sure you have stored your modified version of A1 somewhere on your local machine. After running this cell, your modifications to A1 will be lost.\n",
        "\n",
        "## **WARNING:** Neglecting the warnings above can cause you significant pain and waste of time. **Please run the following cell only once.**\n",
        "\n"
      ],
      "metadata": {
        "id": "WDjqfIlm6s48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PGvtCoDi45RY",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Pulling homework repo.**You will be asked to enter yes or no**.\n",
        "#@markdown Your work on A1 will be lost after running this cell. You may want to\n",
        "#@markdown locally store your last A1 files.\n",
        "#@markdown We will pull the updated A2 folder from the repo.\n",
        "\n",
        "#@markdown Similar to A1, you may be promped to restart your session.\n",
        "#@markdown We will reset the working directory and reload the required modules\n",
        "#@markdown in the following cells.\n",
        "\n",
        "print(\"WARNING: You should run this cell ONLY ONCE for each assignment.\")\n",
        "print(\"WARNING: Please skip this step if you already executed it.\")\n",
        "confirmation = input(\"Are you sure you want to continue? All changes you have made to A1 and A2 will be lost after execution of this cell! (yes/no)\")\n",
        "if confirmation == 'yes':\n",
        "  REPO_PATH = '/content/gdrive/MyDrive/ece421_f2024/ece421fall24_assignments'\n",
        "  %cd $REPO_PATH\n",
        "\n",
        "  !git pull origin main\n",
        "\n",
        "  ASSIGNMENT_PATH = '/content/gdrive/MyDrive/ece421_f2024/ece421fall24_assignments/A2'\n",
        "  %cd $ASSIGNMENT_PATH\n",
        "  %pip install -r requirements_colab.txt\n",
        "else:\n",
        "  print('Skiped this cell. ')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0.3. Importing the required modules\n"
      ],
      "metadata": {
        "id": "VeFCZ-HM9Cbt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2IUYCi_55bf"
      },
      "outputs": [],
      "source": [
        "ASSIGNMENT_PATH = '/content/gdrive/MyDrive/ece421_f2024/ece421fall24_assignments/A2'\n",
        "%cd $ASSIGNMENT_PATH\n",
        "\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "from importlib import reload\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import myTorch\n",
        "import tests_A2\n",
        "import util"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Gradient Descent\n",
        "In the `myTorch.py` file, you will complete the `Optimizer` class implementation, which will be used in the `MultiClassLogisticRegression` class to train a logistic regression model."
      ],
      "metadata": {
        "id": "ezrJakmf7nvF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Optimizer.sgd method\n",
        "In this part, you should implement the `Optimizer.sgd` method.\n",
        "This function computes the update vector that will be used by gradient descent algorithm (*i.e.*, $-\\eta \\nabla_{\\!\\underline{x}}f(\\underline{x}_t)$, where $\\eta$ denotes the learning rate).\n",
        "\n",
        "Useful attributes for implementing this function is:\n",
        "  * `self.lr`: the learning rate.\n",
        "\n",
        "After completing the implementation of `Optimizer.sgd`, run the following cells to execute tests `tests_A2.q1()`, `tests_A2.q2()`, `tests_A2.q3()`, and `tests_A2.q4()`.\n",
        "\n",
        "Note the displayed text outputs and the figures generated by each test. Answer the questions in the handout, accordingly.\n",
        "\n",
        "**Note:** To save the displayed figures, right click on each figure and save it as image.\n"
      ],
      "metadata": {
        "id": "BitHmHc32uZG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e7tHqc87CwG7"
      },
      "outputs": [],
      "source": [
        "#@title q1( ) test\n",
        "\n",
        "#@markdown The test function `q1()` runs your SGD implementation with four\n",
        "#@markdown different learning rates to find\n",
        "#@markdown $$w^\\star = \\underset{w}{\\arg \\min} f(w) = 10w^2 + 20w + 10.$$\n",
        "#@markdown The starting point used by this test is $w_0=5$ and the maximum number\n",
        "#@markdown of iteration is set to $20$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$\n",
        "#@markdown together with some other information on your screen. `q1()` should\n",
        "#@markdown show slow convergence for learning rates $0.001$ and $0.005$, and\n",
        "#@markdown faster convergence with learning rates $0.01$ and $0.05$.\n",
        "\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0TlpvOjCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q2( ) test\n",
        "#@markdown The test function `q2()` runs your SGD implementation with four\n",
        "#@markdown ifferent learning rates to find\n",
        "#@markdown $$w^\\star = \\underset{w}{\\arg \\min} f(w) = 22w^2 + 44w + 22.$$\n",
        "#@markdown The starting point used by this test is $w_0=5$, and the maximum\n",
        "#@markdown number of iteration is set to $35$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other information on your screen. With a correct implementation of SGD, `q2()` must show that SGD stopped after $35$ iteration without meeting the convergence criterion with $\\eta=0.001$ and $\\eta=0.005$. However, with $\\eta = 0.01$, you should be able to find the optimal solution with smaller number of iterations.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pAdpYXlRCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q3( ) test\n",
        "#@markdown The test function `q3()` runs your SGD implementation with four\n",
        "#@markdown different learning rates to find\n",
        "#@markdown $$w^\\star = \\underset{w}{\\arg \\min} f(w) = 10w^2 + 10\\sin(\\pi w).$$\n",
        "#@markdown The starting point used by this test is $w_0=5$, and the maximum\n",
        "#@markdown number of iteration is set to $2000$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other\n",
        "#@markdown information on your screen. With a correct implementation of SGD, `q3()`\n",
        "#@markdown must show that SGD fails to converge to the global optimum point with\n",
        "#@markdown these four learning rate values.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q3()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PHKl3x5CwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q4( ) test\n",
        "#@markdown The test function `q4()` runs your SGD implementation with four\n",
        "#@markdown different learning rates to find\n",
        "#@markdown $$\\underline{w}^\\star = \\underset{\\underline{w}}{\\arg \\min} f(\\underline{w}) = 2w_1^2 + 0.2w_2^2.$$\n",
        "#@markdown The starting point used by this test is $\\underline{w}_0=(3,3)$,\n",
        "#@markdown and the maximum number of iteration is set to $500$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other\n",
        "#@markdown information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q4()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 `Optimizer.heavyball_momentum` and `Optimizer.nestrov_momentum` methods\n",
        "In this part, you should implement the  `Optimizer.heavyball_momentum` method.\n",
        "\n",
        "Note that the implementations of `Optimizer.heavyball_momentum` and `Optimizer.nestrov_momentum` are identical. This is due to the fact that the only difference between these two variants of SGD is in their input gradient vector.\n",
        "\n",
        "You will be implementing the function listed below.\n",
        "  * `heavyball_momentum(self, gradient)`\n",
        "\n",
        "Useful attributes for implementing this function is:\n",
        "  * `self.lr` and `self.gama`: the learning rate and the momentum parameter.\n",
        "  * `self.v`: this attribute can be used to record the last momentum (*i.e.*, update) vector.\n",
        "\n",
        "After completing the implementation of `Optimizer.heavyball_momentum`, run the following cells to execute tests `tests_A2.q5()`, `tests_A2.q6()`, `tests_A2.q7()`, and `tests_A2.q8()`.\n"
      ],
      "metadata": {
        "id": "PEOkB0VZSrNW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn3QyPxSCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q5( ) test\n",
        "#@markdown The test function `q5()` runs your Heavy-ball Momentum implementation\n",
        "#@markdown with four different learning rates to find\n",
        "#@markdown $$w^\\star = \\underset{w}{\\arg \\min} f(w) = 10w^2 + 10\\sin(\\pi w).$$\n",
        "#@markdown The starting point used by this test is $w_0=5$ and the maximum\n",
        "#@markdown number of iteration is set to $2000$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other\n",
        "#@markdown information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q5()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_iGoQltCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q6( ) test\n",
        "#@markdown The test function `q6()` runs your Heavy-ball Momentum implementation\n",
        "#@markdown with four different learning rates to find\n",
        "#@markdown $$\\underline{w}^\\star = \\underset{\\underline{w}}{\\arg \\min} f(\\underline{w}) = 2w_1^2 + 0.2w_2^2.$$\n",
        "#@markdown The starting point used by this test is $\\underline{w}_0=(3,3)$, and\n",
        "#@markdown the maximum number of iteration is set to $500$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other\n",
        "#@markdown information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q6()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P51jgXaQCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q7( ) test\n",
        "#@markdown The test function `q7()` runs the Nestrov Momentum implementation\n",
        "#@markdown with four different learning rates to find\n",
        "#@markdown $$w^\\star = \\underset{w}{\\arg \\min} f(w) = 10w^2 + 10\\sin(\\pi w).$$\n",
        "#@markdown The starting point used by this test is $w_0=5$ and the maximum\n",
        "#@markdown number of iteration is set to $2000$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other\n",
        "#@markdown information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q7()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qMQ6fQcCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q8( ) test\n",
        "#@markdown The test function `q8()` runs your Nestrov Momentum implementation\n",
        "#@markdown with four different learning rates to find\n",
        "#@markdown $$\\underline{w}^\\star = \\underset{\\underline{w}}{\\arg \\min} f(\\underline{w}) = 2w_1^2 + 0.2w_2^2.$$\n",
        "#@markdown The starting point used by this test is $\\underline{w}_0=(3,3)$, and\n",
        "#@markdown the maximum number of iteration is set to $500$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q8()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 `Optimizer.adam` method\n",
        "In this part, you should implement the  `Optimizer.adam` method. See the posted handout for more information about Adam/\n",
        "\n",
        "You will be implementing the function listed below.\n",
        "  * `adam(self, gradient)`\n",
        "\n",
        "Useful attributes for implementing this function is:\n",
        "  * `self.lr`, `self.beta_m`. `self.beta_v` and `self.epsilon`\n",
        "  * `self.m`, `self.v`, and `self.t`\n",
        "\n",
        "Furthermore, useful functions in `NumPy` for implementing this method are:\n",
        "  * `square`  and `sqrt`\n",
        "\n",
        "After completing the implementation of `Optimizer.adam`, run the following cells to execute tests `tests_A2.q9()`, `tests_A2.q10()`, and `tests_A2.q11()`."
      ],
      "metadata": {
        "id": "T14Dyfx-cCX1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NnT_zobCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q9( ) test\n",
        "#@markdown The test function `q9()` runs your Adam implementation with four\n",
        "#@markdown different learning rates to find\n",
        "#@markdown $$w^\\star = \\underset{w}{\\arg \\min} f(w) = 2w_1^2 + 0.2w_2^2.$$\n",
        "#@markdown The starting point used by this test is $\\underline{w}_0=(3,3)$, and\n",
        "#@markdown  the maximum number of iteration is set to $500$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other\n",
        "#@markdown  information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q9()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "355GGmVjCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q10( ) test\n",
        "#@markdown The test function `q10()` runs your Adam implementation with four\n",
        "#@markdown different learning rates to find\n",
        "#@markdown $$\\underline{w}^\\star = \\underset{\\underline{w}}{\\arg \\min} f(\\underline{w}) = 1000(2w_1^2 + 0.2w_2^2).$$\n",
        "#@markdown This function is the scaled version of the function used in test `q9()`.\n",
        "#@markdown The starting point used by this test is $\\underline{w}_0=(3,3)$, and\n",
        "#@markdown the maximum number of iteration is set to $500$.\n",
        "\n",
        "#@markdown This function reports the value of $w^\\star$ together with some other information on your screen.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q10()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnJbMXy1CwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q11( ) test\n",
        "#@markdown The test function `q11()` runs your **Nestrov Momentum** i\n",
        "#@markdown mplementation with four different learning rates to find\n",
        "#@markdown $$\\underline{w}^\\star = \\underset{\\underline{w}}{\\arg \\min} f(\\underline{w}) = 1000(2w_1^2 + 0.2w_2^2).$$\n",
        "#@markdown This function is the same function used in test `q10()`.\n",
        "#@markdown The starting point used by this test is $\\underline{w}_0=(3,3)$, and\n",
        "#@markdown the maximum number of iteration is set to $500$.\n",
        "\n",
        "#@markdown You would most probably see some strange behavior and bunch of errors.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q11()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Multiclass Logistic Regression\n",
        "In the `myTorch.py` file, you will complete the `MultiClassLogisticRegression` class implementation."
      ],
      "metadata": {
        "id": "QAV_5xz5fTdc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Implementing the Multiclass Logistic Regression Model"
      ],
      "metadata": {
        "id": "wHrNfYes7tdt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_hn2i3jUXTs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q12( ) test: Run after implementing `add_bias`\n",
        "#@markdown The following tests your implementation of `add_bias`.\n",
        "#@markdown This function inserts a column of $1$'s to $X$.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q12()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zK8QmP9Q9MrL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q13( ) test: Run after implementing `unique_classes_`, `class_labels_`, and `one_hot test`\n",
        "#@markdown The following tests your implementation of `unique_classes_`,\n",
        "#@markdown `class_labels_`, and `one_hot test`.\n",
        "\n",
        "#@markdown * `unique_classes_`: This function returns a list that contains the\n",
        "#@markdown unique elements in `y`.\n",
        "\n",
        "#@markdown * `class_labels_`: This function returns a dictionary with elements of\n",
        "#@markdown the list `classes` as its keys and a unique integer from $0$ to the\n",
        "#@markdown total number of classed as their values. For instance, if\n",
        "#@markdown `classes = ['blue', 'red', 'yellow']`, then\n",
        "#@markdown `class_labels_(classes) = {'blue': 0, 'red': 1, 'yellow': 2}`\n",
        "\n",
        "#@markdown * `one_hot test`: This function returns the one-hot encoded version\n",
        "#@markdown of `y`.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q13()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0lasLgbrcCc",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q14( ) test: Run after implementing `softmax`\n",
        "#@markdown The following tests your implementation of `softmax`. This function\n",
        "#@markdown is the softmax function, which converts each row of the input matrix\n",
        "#@markdown `z` into a probability distribution. Thus, if\n",
        "#@markdown `z`$\\in \\mathbb{R}^{n \\times c}$ ,then `softmax(z)` returns a matrix\n",
        "#@markdown in $\\mathbb{R}^{n \\times c}$, where each element is non-negative and\n",
        "#@markdown each row of the returned matrix should sum to $1$. Standard `NumPy`\n",
        "#@markdown functions like `exp()`, `sum`, ... can be used.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q14()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1wxL0ooS5bB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Can you manually set the weights parameter?\n",
        "#@markdown A `MultiClassLogisticRegression` object has weights attribute.\n",
        "#@markdown We can set the weights of a `MultiClassLogisticRegression` model by\n",
        "#@markdown setting its `weights` attribute.\n",
        "\n",
        "#@markdown For instance, consider the code in this cell.\n",
        "\n",
        "reload(myTorch)\n",
        "logr = myTorch.MultiClassLogisticRegression()\n",
        "\n",
        "\n",
        "w = np.array([[1, 1, 3],\n",
        "              [3, 1, -2],\n",
        "              [0, 2, 0]])\n",
        "logr.weights = w\n",
        "\n",
        "print(logr.weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5XFoVhNpKh1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q15( ) test: Run after implementing `predict_with_augmented_X`\n",
        "#@markdown The following tests your implementation of `predict_with_augmented_X`.\n",
        "#@markdown This function returns the predicted probability distribution for each\n",
        "#@markdown datapoint in `X`, *i.e.*, each row of `X`, based on the model's weight\n",
        "#@markdown parameter. Note that the input to this function must be an augmented\n",
        "#@markdown input matrix.\n",
        "\n",
        "#@markdown Assuming that input $X \\in \\mathbb{R}^{M \\times (d+1)}$\n",
        "#@markdown and model's weight, *i.e.*, `self.weights` is in\n",
        "#@markdown $\\mathbb{R}^{c \\times (d+1)},$. Note that each row corresponds to the\n",
        "#@markdown weight parameter of a class. `predict_with_X_aug_(X)` returns a matrix\n",
        "#@markdown in $\\mathbb{R}^{M \\times c}$, where each row of it is a valid\n",
        "#@markdown probability distribution.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q15()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmQ8eklb63-x",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q16( ) test: Run after implementing `predict`\n",
        "#@markdown The following tests your implementation of `predict`. This function\n",
        "#@markdown returns the predicted probability distribution for each datapoint in\n",
        "#@markdown `X`, *i.e.*, each row of `X`, based on the model's weight parameter.\n",
        "\n",
        "#@markdown Note that the input to this function is not an augmented input.\n",
        "#@markdown Assuming that input $X \\in \\mathbb{R}^{M \\times (d)}$ and model's\n",
        "#@markdown weight, *i.e.*, `self.weights` is in $\\mathbb{R}^{c \\times (d+1)},$\n",
        "#@markdown`predict(X)` returns a matrix in $\\mathbb{R}^{M \\times c}$, where each\n",
        "#@markdown row of it is a valid probability distribution.\n",
        "\n",
        "#@markdown Useful methods for implementing this method are:\n",
        "#@markdown * `self.add_bias`\n",
        "#@markdown * `self.predict_with_X_aug_`\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECJRGMywCwG8",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q17( ) test: Run after implementing `predict_classes`\n",
        "#@markdown The following tests your implementation of `predict_classes`.\n",
        "#@markdown This function returns the predicted class for each datapoint in `X`,\n",
        "#@markdown *i.e.*, each row of `X`, based on the model's weight parameter.\n",
        "\n",
        "#@markdown Note that the input to this function is not an augmented input.\n",
        "#@markdown Assuming that input $X \\in \\mathbb{R}^{M \\times (d)}$ and model's\n",
        "#@markdown weight, *i.e.*, `self.weights` is in $\\mathbb{R}^{c \\times (d+1)},$\n",
        "#@markdown `predict_classes(X)` returns an `numpy ndarray` with $M$ elements,\n",
        "#@markdown where each element denotes the predicted class for one of the\n",
        "#@markdown datapoints. The predicted class, is the class with highest predicted\n",
        "#@markdown probability.\n",
        "\n",
        "#@markdown Useful methods for implementing this method are `self.predict` and\n",
        "#@markdown `argmax` form `NumPy`\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q17()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m9MQiuvCwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q18( ) test: Run after implementing `score`\n",
        "#@markdown The following tests your implementation of `score`. This function\n",
        "#@markdown returns the ratio of the datapoints in `X` that are correctly\n",
        "#@markdown classified by your model, *i.e.*, the predicted class is derived by\n",
        "#@markdown `predict_classes` function matches the true class specified in `y`.\n",
        "\n",
        "#@markdown Note that `X` is not augmented.\n",
        "\n",
        "#@markdown Useful methods for implementing this method is `self.predict_classes`\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtcBTGhQCwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q19( ) test: Run after implementing `evaluate_`\n",
        "#@markdown The following tests your implementation of `evaluate_`.\n",
        "#@markdown This function returns the ratio of the datapoints that are correctly\n",
        "#@markdown classified by your model. Note that the input data batch to `evaluate_`\n",
        "#@markdown is augmented and the true labels are one-hot-encoded.\n",
        "\n",
        "#@markdown Useful methods for implementing this method are `self.predict_with_X_aug_`\n",
        "#@markdown and `argmax` form `NumPy`.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q19()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7cuS8CK7-hu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q20( ) test: Run after implementing `cross_entropy`\n",
        "#@markdown The following tests your implementation of `cross_entropy`.\n",
        "#@markdown This function returns the cross entropy error given the\n",
        "#@markdown one-hot-encoded version of the true labels and the predicted\n",
        "#@markdown probabilities. Therefore, for a batch of $M$ datapoitns,\n",
        "#@markdown `y_one_hot_encoded` is a $M$ by $c$ matrix and `probs` is a $M$ by\n",
        "#@markdown $c$ matrix, where each row contains the predicted probability\n",
        "#@markdown distribution for a datapoint in the batch.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q20()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--9oxbEZCwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q21( ) test: Run after implementing `compute_grad`\n",
        "#@markdown The following tests your implementation of `compute_grad`.\n",
        "#@markdown Given an augmented batch of data `X` in $\\mathbb{R}^{M\\times (d+1)}$,\n",
        "#@markdown the one-hot-encoded true labels of the data batch,\n",
        "#@markdown and the weight parameters `w` in $\\mathbb{R}^{c \\times (d+1)}$\n",
        "#@markdown where $c$ denote the number of classes,\n",
        "#@markdown this function returns the gradients of $E_{\\text{in}}$ at `w`.\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q21()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwFLoqt2CwG9"
      },
      "source": [
        "## 2.1 Implementing the Learning Algorithm\n",
        "\n",
        "In this part, you will implement the `fit` function. This function fits the logistic regression model to the input dataset.  For more instructions and hints, see the comments in the `myTorch.py` file.  Useful functions in `NumPy` for implementing this method are:\n",
        "  * `random.choice`\n",
        "  * `abs`\n",
        "  * `max`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW8rwQyhCwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q22( ) test: `fit` test with iris dataset. Run after implementing `fit`\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q22()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvNQ7tCbCwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title q23( ) test: `fit` test with digits dataset. Run after implementing `fit`\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "reload(tests_A2)\n",
        "\n",
        "tests_A2.q23()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4iXgakuCwG9"
      },
      "source": [
        "# 3. K-means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph6CUcD-CwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title K-Means small test for simple sanity check\n",
        "#@markdown You can use this small example to manually check if your\n",
        "#@markdown implementation is working properly\n",
        "\n",
        "reload(myTorch)\n",
        "reload(util)\n",
        "\n",
        "x1 = {0:0, 1:0}\n",
        "x2 = {0:0, 1:1}\n",
        "x3 = {0:0, 1:2}\n",
        "x4 = {0:0, 1:3}\n",
        "x5 = {0:0, 1:4}\n",
        "x6 = {0:0, 1:5}\n",
        "examples = [x1, x2, x3, x4, x5, x6]\n",
        "centers, assignments, totalCost = myTorch.kmeans(examples, 2, maxIters=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSkk2j1KCwG9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title K-Means not so small test to check the stability of your solution.\n",
        "#@markdown We just provided the skeleton of the test. You have to modify this\n",
        "#@markdown cell to create a meaningful test on your own.\n",
        "\n",
        "K = 6\n",
        "examples = util.generateClusteringExamples(numExamples=10000, numWordsPerTopic=3, numFillerWords=10000)\n",
        "centers, assignments, totalCost = myTorch.kmeans(examples, K, maxIters=100)\n",
        "\n",
        "averages = []\n",
        "\n",
        "for center in centers:\n",
        "    xs = [examples[i] for i in range(len(examples)) if centers[assignments[i]] == center]\n",
        "    allWords = []\n",
        "    for x in xs:\n",
        "        for key in list(x.keys()):\n",
        "            if key not in allWords:\n",
        "                allWords.append(key)\n",
        "    wordVals = [(word, sum([x[word] for x in xs])*1.0/len(xs)) for word in allWords]\n",
        "    avg = dict(wordVals)\n",
        "    averages.append(avg)\n",
        "\n",
        "# study averages to check if your solution is stable."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}